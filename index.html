<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <center><titlt><h1>***DOCUMENTARY***</h1></titlt></center>
<marquee>31R Documentary</marquee>
<hr/>
<H1><b>*FULLSTACK*</b></H1>
<P>Fullstack Academy is an immersive software engineering coding bootcamp located in New York City.[1] Students of the full-time flagship course learn full stack JavaScript over the course of a 13-week, on-campus program. Fullstack Academy offers beginner courses in JavaScript (JavaScript Jumpstart)[2] and front-end development,[3] as well as a summer program for college-age students (Summer of Code), and a part-time version of their full-time curriculum (Flex).[4]
    <H1><b>History</b></H1>
    is an immersive software engineering coding bootcamp located in New York City.[1] Students of the full-time flagship course learn full stack JavaScript over the course of a 13-week, on-campus program. Fullstack Academy offers beginner courses in JavaScript (JavaScript Jumpstart)[2] and front-end development,[3] as well as a summer program for college-age students (Summer of Code), and a part-time version of their full-time curriculum (Flex).[4]
    Fullstack Academy was founded in 2012 by David Yang (formerly of Yahoo!, Gilt)[5] and Wharton School alumnus Nimit Maru (formerly of Yahoo!, Bloomspot).[6] The company joined the Spring 2012 cohort of Y-Combinator.[7] The following year, Fullstack opened to students.[8] In 2019, Fullstack Academy was acquired by Bridgepoint Education.[9] Founders David Yang and Nimit Maru left the company in 2021. As of 2021, Fullstack no longer offers an in-person bootcamp in Chicago.[1]
    
    <H1><B>Course offerings</B></H1>
    Fullstack's flagship immersive course begins with a four-week "foundations" course, to be completed remotely before arriving on-campus. The on-site component of the program involves thirteen weeks of intensive JavaScript education, incorporating a lecture-workshop format, as well as a team-based project phase.[10] Back-end languages taught include Node.js/Express; front end languages include React.js/JavaScript MVC, HTML5, and CSS3; and Data Structures taught include MONGODB, NoSQL, and Postgres. Full-time students have access to career assistance following graduation. Tuition for the full-time immersive is $17,610.[4][11]
    The Flex-Immersive is a part-time course covering the same content as Fullstack Academy's full-time program. The foundations course and career assistance programs are also available to Flex students.[12]
    
    Summer of Code is an immersive course for college and graduate school students with computer science or technically equivalent experience, held each year between June and August.[4] The course is full-time and adheres to the same curriculum and structure as the flagship immersive program.[13]
    
    <H1><B>Admissions</B></H1>
    Fullstack Academy's immersive courses (Full-Time, Flex-Immersive, & Summer of Code) use selective admissions procedures, admitting approximately 8% of applicants.[14]
    
    Applicants for the Full-time Immersive, Flex, and Summer of Code programs must pass a fundamental-skills evaluation, technical interview, and in-person interview prior to program acceptance.[15]
    
    Awards and media
    Fullstack Academy was named Best Coding Bootcamp of 2015 by SkilledUp.com.[16] Fullstack, its co-founders, and former students have received media coverage from Forbes.com,[17] The Huffington Post,[18] Business Insider,[8] VentureBeat.com,[19] and Fox5NY.[20]
    
    See also
    Web Development
    References
     <li>"Fullstack Academy". Fullstack Academy. 2015-09-12. Retrieved 2021-03-25.</li>
     <li>"JavaScript Jumpstart – Master the Fundamentals of JavaScript". Fullstack Academy. 2015-04-06. Retrieved 2015-10-30.</li>
     <li>"Introduction to Front-End Development". Fullstack Academy. 2015-04-06. Retrieved 2015-10-30.</li>
     <li>"Fullstack Academy | Reviews, Courses, and News". Course Report. Retrieved 2015-10-30.</li>
     David Yang. "David Yang: Executive Profile & Biography – Businessweek". Bloomberg.com. Retrieved 2015-10-30.
     "List of Private Companies Worldwide, Letter – Businessweek". Bloomberg.com. Retrieved 2015-10-30.
     <li>"Fullstack Academy". Y Combinator. Retrieved 2023-04-29.</li>
     "4 traits that make developers desirable by employers". Business Insider. 2015-07-25. Retrieved 2015-10-30.
     <li>"Bridgepoint Education Acquires a Coding Bootcamp in Fullstack Academy". EdSurge News. 2019-03-12. Retrieved 2021-03-25.</li>
     "Top coding bootcamp in New York and Chicago". 2015-09-12. Archived from the original on September 26, 2015. Retrieved September 25, 2015.
     <li>"Frequently Asked Questions". Fullstackacademy.com. 2014-12-19. Retrieved 2015-10-30.</li>
     <li> "Learn Web Development at these 10 Part-Time Bootcamps". Course Report. Retrieved 2015-10-30.</li>
    <li> Bellamy, Ebony (2015-02-26). "Fullstack Academy Offering Students a Summer of Code". SkilledUp. Retrieved 2015-10-30.</li>
    <li>Toscano, Nick. "The Ultimate Guide to Coding Bootcamps: The Exhaustive List". Skilledup.com. Archived from the original on 2015-10-31. Retrieved 2015-10-30.</li>
    <li>"Apply to Fullstack Academy". Fullstackacademy.com. 2015-09-13. Retrieved 2015-10-30.</li>
    <li> "Fullstack Academy: Winner Skillies Bootcamp Award". SkilledUp. 2015-03-24. Retrieved 2015-10-30.</li>
    <li>"Why Women Are Choosing Coding Bootcamps". Forbes.com. Retrieved 2015-10-30.</li>
    <li> "Coding School: When Your School Project Lands You the Job | Robin Raskin". Huffingtonpost.com. 2015-08-19. Retrieved 2015-10-30.</li>
     Robert McGuire (2014-06-26). "Hacking the hacker school: How the bootcamp is being taken to scale outside the coding world | VentureBeat | Dev | by J. O'Dell". VentureBeat. Retrieved 2015-10-30.
     "Fullstack Academy – Fox 5 News Feature: Hiring Day July 2015". YouTube. 2015-07-16. Retrieved 2015-10-30.</P>
     <HR/>
     <H1>***THREE(3) TIER ARCHITECTURE***</H1>
     <h1><b>Multitier architecture</b></h1>
     <p>From Wikipedia, the free encyclopedia
        Several terms redirect here. For other uses, see Three-tier system (disambiguation), Tier 1 (disambiguation), Tier 2 (disambiguation), Tier 3 (disambiguation), and Tier 4 (disambiguation).
        
        <p><This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.
        Find sources:<b>"Multitier architecture"</b> – news · newspapers · books · scholar · JSTOR (January 2008) (Learn how and when to remove this message)
        In software engineering, multitier architecture (often referred to as n-tier architecture) is a client–server architecture in which presentation, application processing and data management functions are physically separated. The most widespread use of multitier architecture is the three-tier architecture (for example, Cisco's Hierarchical internetworking model).
        <b>N-tier application</b> architecture provides a model by which developers can create flexible and reusable applications. By segregating an application into tiers, developers acquire the option of modifying or adding a specific tier, instead of reworking the entire application.</p> N-tier architecture is a good fit for small and simple applications because of its simplicity and low-cost. Also, it can be a good starting point when architectural requirements are not clear yet.[1][2] A three-tier architecture is typically composed of a presentation tier, a logic tier, and a data tier.
        While the concepts of layer and tier are often used interchangeably, one fairly common point of view is that there is indeed a difference. This view holds that a layer is a logical structuring mechanism for the conceptual elements that make up the software solution, while a tier is a physical structuring mechanism for the hardware elements that make up the system infrastructure.[3][4] For example, a three-layer solution could easily be deployed on a single tier, such in the case of an extreme database-centric architecture called RDBMS-only architecture[5] or in a personal workstation.[6]
        
       <h1><b>Layers</b></h1>
        The "Layers" architectural pattern has been described in various publications.[7]
        <h1><b>Common layaer</b></h1>
        <P>In a logical multilayer architecture for an information system with an object-oriented design, the following four are the most common:
        
      <strong> Presentation layer (a.k.a. UI layer, view layer, presentation tier in multitier architecture)
        Application layer (a.k.a. service layer[8][9] or GRASP Controller Layer [10])
        Business layer (a.k.a. business logic layer (BLL), domain logic layer)
        Data access layer (a.k.a. persistence layer, logging, networking, and other services which are required to support a particular business layer)
        The book Domain Driven Design describes some common uses for the above four layers, although its primary focus is the domain layer.</strong>
        
        If the application architecture has no explicit distinction between the business layer and the presentation layer (i.e., the presentation layer is considered part of the business layer), then a traditional client-server (two-tier) model has been implemented.[citation needed]
        
        The more usual convention is that the application layer (or service layer) is considered a sublayer of the business layer, typically encapsulating the API definition surfacing the supported business functionality. The application/business layers can, in fact, be further subdivided to emphasize additional sublayers of distinct responsibility. For example, if the model–view–presenter pattern is used, the presenter sublayer might be used as an additional layer between the user interface layer and the business/application layer (as represented by the model sublayer).[citation needed]
        
        Some also identify a separate layer called the business infrastructure layer (BI), located between the business layer(s) and the infrastructure layer(s).</P>
         It is also sometimes called the "low-level business layer" or the "business services layer". This layer is very general and can be used in several application tiers (e.g. a CurrencyConverter).[12]
        
        The infrastructure layer can be partitioned into different levels (high-level or low-level technical services).[12] Developers often focus on the persistence (data access) capabilities of the infrastructure layer and therefore only talk about the persistence layer or the data access layer (instead of an infrastructure layer or technical services layer). In other words, the other kind of technical services is not always explicitly thought of as part of any particular layer.[citation needed]. The Data Access layer normally contains an object known as the Data Access Object (DAO).
        
        A layer is on top of another, because it depends on it. Every layer can exist without the layers above it, and requires the layers below it to function. Another common view is that layers do not always strictly depend on only the adjacent layer below. For example, in a relaxed layered system (as opposed to a strict layered system) a layer can also depend on all the layers below it.[7] The relaxed layered system has more couplings and subsequently it's more difficult to change. Multi-tier architectures can use a hybrid approach so that some layers are strict while other layers are relaxed.[13][14]
        
        <h3>Three-tier architecture </h3>
        
        Overview of a three-tier application.
        Three-tier architecture is a client-server software architecture pattern in which the user interface (presentation), functional process logic ("business rules"), computer data storage and data access are developed and maintained as independent modules, most often on separate platforms.[15] It was developed by John J. Donovan in Open Environment Corporation (OEC), a tools company he founded in Cambridge, Massachusetts.
        
        Apart from the usual advantages of modular software with well-defined interfaces, the three-tier architecture is intended to allow any of the three tiers to be upgraded or replaced independently in response to changes in requirements or technology. For example, a change of operating system in the presentation tier would only affect the user interface code.
        
        Typically, the user interface runs on a desktop PC or workstation and uses a standard graphical user interface, functional process logic that may consist of one or more separate modules running on a workstation or application server, and an RDBMS on a database server or mainframe that contains the computer data storage logic. The middle tier may be multitiered itself (in which case the overall architecture is called an "n-tier architecture").[16]
        <h1>Three-tier architecture</h1>

Overview of a three-tier application.
Three-tier architecture is a client-server software architecture pattern in which the user interface (presentation), functional process logic ("business rules"), computer data storage and data access are developed and maintained as independent modules, most often on separate platforms.[15] It was developed by John J. Donovan in Open Environment Corporation (OEC), a tools company he founded in Cambridge, Massachusetts.

Apart from the usual advantages of modular software with well-defined interfaces, the three-tier architecture is intended to allow any of the three tiers to be upgraded or replaced independently in response to changes in requirements or technology. For example, a change of operating system in the presentation tier would only affect the user interface code.

Typically, the user interface runs on a desktop PC or workstation and uses a standard graphical user interface, functional process logic that may consist of one or more separate modules running on a workstation or application server, and an RDBMS on a database server or mainframe that contains the computer data storage logic. The middle tier may be multitiered itself (in which case the overall architecture is called an "n-tier architecture").[16]
        <h2>Presentation tier</h2>
        This is the topmost level of the application. The presentation tier displays information related to such services as browsing merchandise, purchasing and shopping cart contents. It communicates with other tiers by which it puts out the results to the browser/client tier and all other tiers in the network. In simple terms, it is a layer that users can access directly (such as a web page, or an operating system's GUI).
        <h1>Application tier (business logic, logic tier, or middle tier)</h1>
        The logical tier is pulled out from the presentation tier and, as its layer, it controls an application’s functionality by performing detailed processing.
        <h1>Data tier</h1>
        The data tier includes the data persistence mechanisms (database servers, file shares, etc.) and the data access layer that encapsulates the persistence mechanisms and exposes the data. The data access layer should provide an API to the application tier that exposes methods of managing the stored data without exposing or creating dependencies on the data storage mechanisms. Avoiding dependencies on the storage mechanisms allows for updates or changes without the application tier clients being affected by or even aware of the change. As with the separation of any tier, there are costs for implementation and often costs to performance in exchange for improved scalability and maintainability.
        <h1><b>Web development usage</b></h1>
        In the web development field, three-tier is often used to refer to websites, commonly electronic commerce websites, which are built using three tiers:
        
        A front-end web server serving static content, and potentially some cached dynamic content. In web-based application, front end is the content rendered by the browser. The content may be static or generated dynamically.
        A middle dynamic content processing and generation level application server (e.g., Symfony, Spring, ASP.NET, Django, Rails, Node.js).
        A back-end database or data store, comprising both data sets and the database management system software that manages and provides access to the data.
        Other considerations
        Data transfer between tiers is part of the architecture. Protocols involved may include one or more of SNMP, CORBA, Java RMI, .NET Remoting, Windows Communication Foundation, sockets, UDP, web services or other standard or proprietary protocols. Often middleware is used to connect the separate tiers. Separate tiers often (but not necessarily) run on separate physical servers, and each tier may itself run on a cluster.
        
        <h1><b>Traceability</b></h1>
        The end-to-end traceability of data flows through n-tier systems is a challenging task which becomes more important when systems increase in complexity. The Application Response Measurement defines concepts and APIs for measuring performance and correlating transactions between tiers. Generally, the term "tiers" is used to describe physical distribution of components of a system on separate servers, computers, or networks (processing nodes). A three-tier architecture then will have three processing nodes. The term "layers" refers to a logical grouping of components which may or may not be physically located on one processing node.
        
       <h1> See also</h1>
        Abstraction layer
        Client–server model
        Database-centric architecture
        Front-end and back-end
        Load balancing (computing)
        Monolithic application
        Open Services Architecture
        Rich web application
        Service layer
        Shearing layers
        Web application
       <h1> References</h1>
         Richards, Mark (2020). Fundamentals of Software Architecture: An Engineering Approach (1st ed.). O'Reilly Media. ISBN 978-1492043454.
         Richards, Mark (2022). Software Architecture Patterns. O'Reilly Media, Inc. ISBN 9781098134273.
         Deployment Patterns (Microsoft Enterprise Architecture, Patterns, and Practices)
         Fowler, Martin "Patterns of Enterprise Application Architecture" (2002). Addison Wesley.
         Vicente, Alfonso; Etcheverry, Lorena; Sabiguero, Ariel (2021). "An RDBMS-only architecture for web applications". 2021 XLVII Latin American Computing Conference (CLEI). pp. 1–9. doi:10.1109/CLEI53233.2021.9640017. ISBN 978-1-6654-9503-5. S2CID 245387844.
         Deployment Patterns (Microsoft Enterprise Architecture, Patterns, and Practices)
         Buschmann, Frank; Meunier, Regine; Rohnert, Hans; Sommerlad, Peter; Stal, Michael (1996-08). Pattern-Oriented Software Architecture, Volume 1, A System of Patterns. Wiley, August 1996. ISBN 978-0-471-95869-7. Retrieved from http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471958697.html.
         Martin Fowler's Service Layer
         Martin Fowler explains that Service Layer is the same as Application Layer
         Comparison/discussion of the GRASP Controller Layer vs. Application/Service Layer
         Domain-Driven Design, the Book pp. 68-74. Retrieved from http://www.domaindrivendesign.org/books#DDD.
         Applying UML and Patterns, 3rd edition, page 203 ISBN 0-13-148906-2
         Richards, Mark (March 3, 2020). Fundamentals of Software Architecture: An Engineering Approach (1st ed.). O'Reilly Media. ISBN 978-1492043454.
         Richards, Mark. Software Architecture Patterns. O'Reilly Media, Inc.
         Eckerson, Wayne W. "Three Tier Client/Server Architecture: Achieving Scalability, Performance, and Efficiency in Client Server Applications." Open Information Systems 10, 1 (January 1995): 3(20)
         This article is based on material taken from three-tier at the Free On-line Dictionary of Computing prior to 1 November 2008 and incorporated under the "relicensing" terms of the GFDL, version 1.3 or later.</p>
    
    <hr/>
<h1>***APPLICATION PROGRAMMING INTERFACE (API)***</h1>
<P>An <B>application programming interface</B> (API) is a set of functions, procedures, methods or classes used by <strong>computer programs</strong> to request services from the operating system, software libraries or any other service providers running on the computer. A computer programmer uses the API to make application programs.

    An API works [1] by communicating with and exchanging data with other systems, acting as a messenger between the user and the system to retrieve the necessary data the user is requesting from the system.
    
   <h1> Main types of web APIs:</h1>[2]
    
    Open <b>APIs - available </b>to the public; they can be accessed by any external users.
    Partner APIs - available to strategic business partners; they are exposed to a public API developer portal.
    Internal APIs - available to a company's internal development teams; they are exposed to a private API developer portal.
    Composite APIs - are a sequence of tasks bundled into a single API call.
    Types of API include web services API like the Twitter API, which allows programs to use the API to receive updates on tweets.
    
    <h1>References</h1>
     Rajdeep, Singh (2022-07-23). "How API Integration Works?". Suffescom. Archived from the original on 2024-11-22. Retrieved 2024-11-22.
     Defranchi, Lydia (2024-03-28). "Different types of APIs explained: styles, protocols, audiences + real-life examples". Axway Software. Archived from the original on 2022-08-17. Retrieved 2020-04-30.
     This short article about technology can be made longer. You can help Wikipedia by adding to it.</P>
<hr/>
<h1>***DEVOPS***</h1>
<P><b>DevOps</b> is a methodology integrating and automating the work of software development (Dev) and information technology operations (Ops). It serves as a means for improving and shortening the systems development life cycle.[1] DevOps is complementary to agile software development; several DevOps aspects came from the agile approach.

    Automation is an important part of DevOps. Software programmers and architects should use "fitness functions" to keep their software in check.[2]
    
    According to Neal Ford, DevOps, particularly through continuous delivery, employs the "Bring the pain forward" principle, tackling tough tasks early, fostering automation and swift issue detection. [3]
    
    <h1>Definition</h1>
    Other than it being a cross-functional combination (and a portmanteau) of the terms and concepts for "development" and "operations", academics and practitioners have not developed a universal definition for the term "DevOps".[a][b][c][d] Most often, DevOps is characterized by key principles: shared ownership, workflow automation, and rapid feedback. From an academic perspective, Len Bass, Ingo Weber, and Liming Zhu—three computer science researchers from the CSIRO and the Software Engineering Institute—suggested defining DevOps as "a set of practices intended to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality".[7] However, the term is used in multiple contexts. At its most successful, DevOps is a combination of specific practices, culture change, and tools.[8]
    
   <h1>History</h1>
    Proposals to combine software development methodologies with deployment and operations concepts began to appear in the late 80s and early 90s.[9]
    
    Around 2007 and 2008, concerns were raised by those within the software development and IT communities that the separation between the two industries, where one wrote and created software entirely separate from those that deploy and support the software was creating a fatal level of dysfunction within the industry.[10]
    
    In 2009, the first conference named DevOps Days was held in Ghent, Belgium. The conference was founded by Belgian consultant, project manager and agile practitioner Patrick Debois.[11][12] The conference has now spread to other countries.[13]
    
    In 2012, a report called "State of DevOps" was first published by Alanna Brown at Puppet Labs.[14][15]
    
    As of 2014, the annual State of DevOps report was published by Nicole Forsgren, Gene Kim, Jez Humble and others. They stated that the adoption of DevOps was accelerating.[16][17] Also in 2014, Lisa Crispin and Janet Gregory wrote the book More Agile Testing, containing a chapter on testing and DevOps.[18][19]
    
    In 2016, the DORA metrics for throughput (deployment frequency, lead time for changes), and stability (mean time to recover, change failure rate) were published in the State of DevOps report.[14] However, the research methodology and metrics were criticized by experts.[20][21][22][23] In response to these criticisms, the 2023 State of DevOps report [24] published changes that updated the stability metric "mean time to recover" to "failed deployment recovery time" acknowledging the confusion the former metric has caused.[25]
    
   <h2> Relevant metrics</h2>
    DORA metrics are a set of key metrics developed by DevOps Research and Assessment (DORA) which can help to measure software development efficiency and reliability. These metrics include: [26]
    
    Deployment Frequency: Time between code deployments.
    Mean Lead Time for Changes: Time between code commit and deployment.
    Change Failure Rate: Percentage of deployments causing production issues.
    Mean Time To Recovery: Time to resolve production issues.
    Reliability (added in 2021): [27] Measures operational performance, focusing on availability and adherence to user expectations.
    These metrics, when applied appropriately and within relevant context, facilitate insights into DevOps performance, enabling teams to optimize deployment speed, reliability and quality, thereby informing data-driven decisions to enhance software development processes. [26]
    
    <h2>Relationship to other approaches</h2>
    Many of the ideas fundamental to DevOps practices are inspired by, or mirror, other well known practices such as Lean and Deming's Plan-Do-Check-Act cycle, through to The Toyota Way and the Agile approach of breaking down components and batch sizes.[28] Contrary to the "top-down" prescriptive approach and rigid framework of ITIL in the 1990s, DevOps is "bottom-up" and flexible, having been created by software engineers for their own needs.[29]
    
    <h2>Agile</h2>
    Main article: Agile software development
    The motivations for what has become modern DevOps and several standard DevOps practices such as automated build and test, continuous integration, and continuous delivery originated in the Agile world, which dates (informally) to the 1990s, and formally to 2001. Agile development teams using methods such as extreme programming couldn't "satisfy the customer through early and continuous delivery of valuable software"[30] unless they took responsibility for operations and infrastructure for their applications, automating much of that work. Because Scrum emerged as the dominant Agile framework in the early 2000s and it omitted the engineering practices that were part of many Agile teams, the movement to automate operations and infrastructure functions splintered from Agile and expanded into what has become modern DevOps. Today, DevOps focuses on the deployment of developed software, whether it is developed using Agile oriented methodologies or other methodologies.
    
   <h2> ArchOps</h2>
    ArchOps presents an extension for DevOps practice, starting from software architecture artifacts, instead of source code, for operation deployment.[31] ArchOps states that architectural models are first-class entities in software development, deployment, and operations.
    
   <h2>Continuous Integration and Delivery (CI/CD)</h2>
    Main article: CI/CD
    Automation is a core principle for achieving DevOps success and CI/CD is a critical component.[32] Plus, improved collaboration and communication between and within teams helps achieve faster time to market, with reduced risks.[33]
    
    <h2>Mobile DevOps</h2>
    Main article: Mobile DevOps
    Mobile DevOps is a set of practices that applies the principles of DevOps specifically to the development of mobile applications. Traditional DevOps focuses on streamlining the software development process in general, but mobile development has its own unique challenges that require a tailored approach.[34] Mobile DevOps is not simply as a branch of DevOps specific to mobile app development, instead an extension and reinterpretation of the DevOps philosophy due to very specific requirements of the mobile world.
    
    <h2>Site-reliability engineering</h2>
    Main article: Site reliability engineering
    In 2003, Google developed site reliability engineering (SRE), an approach for releasing new features continuously into large-scale high-availability systems while maintaining high-quality end-user experience.[35] While SRE predates the development of DevOps, they are generally viewed as being related to each other. Some of the original authors of the discipline consider SRE as an implementation of DevOps.[36]
    
    <h2>Toyota production system, lean thinking, kaizen</h2>
    Main article: Toyota Production System
    Toyota production system, also known under the acronym TPS, was the inspiration for lean thinking with its focus on continuous improvement, kaizen, flow and small batches. The andon cord principle to create fast feedback, swarm and solve problems stems from TPS.[37][38]
    
    <h2>DevSecOps, shifting security left</h2>
    DevSecOps is an augmentation of DevOps to allow for security practices to be integrated into the DevOps approach. Contrary to a traditional centralized security team model, each delivery team is empowered to factor in the correct security controls into their software delivery. Security practices and testing are performed earlier in the development lifecycle, hence the term "shift left". Security is tested in three main areas: static, software composition, and dynamic.
    
    Checking software statically via static application security testing (SAST) is white-box testing with special focus on security. Depending on the programming language, different tools are needed to do such static code analysis. The software composition is analyzed, especially libraries, and the version of each component is checked against vulnerability lists published by CERT and other expert groups. When giving software to clients, library licenses and their match to the license of the software distributed are in focus, especially copyleft licenses.
    
    In dynamic testing, also called black-box testing, software is tested without knowing its inner functions. In DevSecOps this practice may be referred to as dynamic application security testing (DAST) or penetration testing. The goal is early detection of defects including cross-site scripting and SQL injection vulnerabilities. Threat types are published by the open web application security project, e.g. its TOP10,[39] and by other bodies.
    
    DevSecOps has also been described as a cultural shift involving a holistic approach to producing secure software by integrating security education, security by design, and security automation.[40]
    
    <h2>Cultural change</h2>
    DevOps initiatives can create cultural changes in companies[41] by transforming the way operations, developers, and testers collaborate during the development and delivery processes.[42] Getting these groups to work cohesively is a critical challenge in enterprise DevOps adoption.[43][44] DevOps is as much about culture as it is about the toolchain.[45]
    
    <h2>Microservices</h2>
    Although in principle it is possible to practice DevOps with any architectural style, the microservices architectural style is becoming the standard for building continuously deployed systems. Small size service allows the architecture of an individual service to emerge through continuous refactoring.[46]
    
    <h2>DevOps automation</h2>
    It also supports consistency, reliability, and efficiency within the organization, and is usually enabled by a shared code repository or version control. As DevOps researcher Ravi Teja Yarlagadda hypothesizes, "Through DevOps, there is an assumption that all functions can be carried out, controlled, and managed in a central place using a simple code."[47]
    
   <h2> Automation with version control</h2>
    Many organizations use version control to power DevOps automation technologies like virtual machines, containerization (or OS-level virtualization), and CI/CD. The paper "DevOps: development of a toolchain in the banking domain" notes that with teams of developers working on the same project, "All developers need to make changes to the same codebase and sometimes edit even the same files. For efficient working, there has to be a system that helps engineers avoid conflicts and retain the codebase history,"[48] with the Git version control system and the GitHub platform referenced as examples.
    
   <h2> GitOps</h2>
    GitOps evolved from DevOps. The specific state of deployment configuration is version-controlled. Because the most popular version-control is Git, GitOps' approach has been named after Git. Changes to configuration can be managed using code review practices, and can be rolled back using version-controlling. Essentially, all of the changes to a code are tracked, bookmarked, and making any updates to the history can be made easier. As explained by Red Hat, "visibility to change means the ability to trace and reproduce issues quickly, improving overall security."[49]
    
    <h2>Best practices for cloud systems</h2>
    The following practices can enhance productivity of DevOps pipelines, especially in systems hosted in the cloud: [50][51][52]
    
    1.<b>Number of Pipelines</b>:Small teams can be more productive by having one repository and one pipeline. In contrast, larger organizations may have separate repositories and pipelines for each team or even separate repositories and pipelines for each service within a team.
    2.<b>Permissions</b>: In the context of pipeline-related permissions, adhering to the principle of least privilege can be challenging due to the dynamic nature of architecture. Administrators may opt for more permissive permissions while implementing compensating security controls to minimize the blast radius.
    <h2>See also</h2>
    DataOps
    DevOps toolchain
    Twelve-Factor App methodology
    Infrastructure as code
    Lean software development
    Site reliability engineering
    Value stream
    List of build automation software
   <h2>Notes</h2>
     Dyck et al. (2015) "To our knowledge, there is no uniform definition for the terms release engineering and DevOps. As a consequence, many people use their own definitions or rely on others, which results in confusion about those terms."[4]
     Jabbari et al. (2016) "The research results of this study showed the need for a definition as individual studies do not consistently define DevOps."[5]
     Erich et al. (2017) "We noticed that there are various gaps in the study of DevOps: There is no consensus of what concepts DevOps covers, nor how DevOps is defined."[6]
     Erich et al. (2017) "We discovered that there exists little agreement about the characteristics of DevOps in the academic literature."[6]</P>

<hr/>
<h1>***AGILE SOFTWARE DEVELOPMENT***</h1>
<P><B>Agile software development</B> is an umbrella term for approaches to developing software that reflect the values and principles agreed upon by The Agile Alliance, a group of 17 software practitioners in 2001.[1] As documented in their Manifesto for Agile Software Development the practitioners value:[2]

    1.<b>Individuals and interactions over processes and tools
    Working software over comprehensive documentation
    Customer collaboration over contract negotiation
    Responding to change over following a plan</b>
    The practitioners cite inspiration from new practices at the time including extreme programming, scrum, dynamic systems development method, adaptive software development and being sympathetic to the need for an alternative to documentation driven, heavyweight software development processes. [3]
    
    Many software development practices emerged from the agile mindset. These agile-based practices, sometimes called Agile (with a capital A)[4] include requirements, discovery and solutions improvement through the collaborative effort of self-organizing and cross-functional teams with their customer(s)/end user(s).[5][6]
    
    While there is much anecdotal evidence that the agile mindset and agile-based practices improve the software development process, the empirical evidence is limited and less than conclusive.[7][8][9]
    
    <h2>History</h2>
    Iterative and incremental software development methods can be traced back as early as 1957,[10] with evolutionary project management[11][12] and adaptive software development[13] emerging in the early 1970s.[14]
    
    During the 1990s, a number of lightweight software development methods evolved in reaction to the prevailing heavyweight methods (often referred to collectively as waterfall) that critics described as overly regulated, planned, and micromanaged.[15] These lightweight methods included: rapid application development (RAD), from 1991;[16][17] the unified process (UP) and dynamic systems development method (DSDM), both from 1994; Scrum, from 1995; Crystal Clear and extreme programming (XP), both from 1996; and feature-driven development (FDD), from 1997. Although these all originated before the publication of the Agile Manifesto, they are now collectively referred to as agile software development methods.[3]
    
    Already since 1991 similar changes had been underway in manufacturing[18][19] and management thinking[20] derived from Lean management.
    
    In 2001, seventeen software developers met at a resort in Snowbird, Utah to discuss lightweight development methods. They were: Kent Beck (Extreme Programming), Ward Cunningham (Extreme Programming), Dave Thomas (Pragmatic Programming, Ruby), Jeff Sutherland (Scrum), Ken Schwaber (Scrum), Jim Highsmith (Adaptive Software Development), Alistair Cockburn (Crystal), Robert C. Martin (SOLID), Mike Beedle (Scrum), Arie van Bennekum, Martin Fowler (OOAD and UML), James Grenning, Andrew Hunt (Pragmatic Programming, Ruby), Ron Jeffries (Extreme Programming), Jon Kern, Brian Marick (Ruby, Test-driven development), and Steve Mellor (OOA). The group, The Agile Alliance, published the Manifesto for Agile Software Development.[2]
    
    In 2005, a group headed by Cockburn and Highsmith wrote an addendum of project management principles, the PM Declaration of Interdependence,[21] to guide software project management according to agile software development methods.
    
    In 2009, a group working with Martin wrote an extension of software development principles, the Software Craftsmanship Manifesto, to guide agile software development according to professional conduct and mastery.
    
    In 2011, the Agile Alliance created the Guide to Agile Practices (renamed the Agile Glossary in 2016),[22] an evolving open-source compendium of the working definitions of agile practices, terms, and elements, along with interpretations and experience guidelines from the worldwide community of agile practitioners.
    
    <h2>Values and principles </h2>
    <b>Values</b>
    The agile manifesto reads:[2]
    
    We are uncovering better ways of developing software by doing it and helping others do it. Through this work we have come to value:
    
   <B> Individuals and interactions over processes and tools
    Working software over comprehensive documentation
    Customer collaboration over contract negotiation
    Responding to change over following a plan</B>
    That is, while there is value in the items on the right, we value the items on the left more.
    
    <h2>Scott Ambler explained</h2>:[23]
    
    Tools and processes are important, but it is more important to have competent people working together effectively.
    Good documentation is useful in helping people to understand how the software is built and how to use it, but the main point of development is to create software, not documentation.
    A contract is important but is not a substitute for working closely with customers to discover what they need.
    A project plan is important, but it must not be too rigid to accommodate changes in technology or the environment, stakeholders' priorities, and people's understanding of the problem and its solution.
    Introducing the manifesto on behalf of the Agile Alliance, <B>Jim Highsmith</B> said,
    
    The Agile movement is not anti-methodology, in fact many of us want to restore credibility to the word methodology. We want to restore a balance. We embrace modeling, but not in order to file some diagram in a dusty corporate repository. We embrace documentation, but not hundreds of pages of never-maintained and rarely-used tomes. We plan, but recognize the limits of planning in a turbulent environment. Those who would brand proponents of XP or SCRUM or any of the other Agile Methodologies as "hackers" are ignorant of both the methodologies and the original definition of the term hacker.
    
   <center><b>— Jim Highsmith, History: The Agile Manifesto-</b></center>[24]
   <h2> Principles</h2>
    The values are based on these principles:[25]
    <center>
    Customer satisfaction by early and continuous delivery of valuable software.
    Welcome changing requirements, even in late development.
    Deliver working software frequently (weeks rather than months).
    Close, daily cooperation between business people and developers.
    Projects are built around motivated individuals, who should be trusted.
    Face-to-face conversation is the best form of communication (co-location).
    Working software is the primary measure of progress.
    Sustainable development, able to maintain a constant pace.
    Continuous attention to technical excellence and good design.
    Simplicity—the art of maximizing the amount of work not done—is essential.
    Best architectures, requirements, and designs emerge from self-organizing teams.
    Regularly, the team reflects on how to become more effective, and adjusts accordingly.</center>
    <h2>Overview</h2>
    <b>Iterative, incremental, and evolutionary</b>
    Most agile development methods break product development work into small increments that minimize the amount of up-front planning and design. Iterations, or sprints, are short time frames (timeboxes)[26] that typically last from one to four weeks.[27]: 20  Each iteration involves a cross-functional team working in all functions: planning, analysis, design, coding, unit testing, and acceptance testing. At the end of the iteration a working product is demonstrated to stakeholders. This minimizes overall risk and allows the product to adapt to changes quickly.[28][29] An iteration might not add enough functionality to warrant a market release, but the goal is to have an available release (with minimal bugs) at the end of each iteration.[30] Through incremental development, products have room to "fail often and early" throughout each iterative phase instead of drastically on a final release date.[31] Multiple iterations might be required to release a product or new features. Working software is the primary measure of progress.[25]
    
    A key advantage of agile approaches is speed to market and risk mitigation. Smaller increments are typically released to market, reducing the time and cost risks of engineering a product that doesn't meet user requirements.
    
   <h2><b> Efficient and face-to-face communication</b></h2>
    The 6th principle of the agile manifesto for software development states "The most efficient and effective method of conveying information to and within a development team is face-to-face conversation". The manifesto, written in 2001 when video conferencing was not widely used, states this in relation to the communication of information, not necessarily that a team should be co-located.
    
    The principle of co-location is that co-workers on the same team should be situated together to better establish the identity as a team and to improve communication.[32] This enables face-to-face interaction, ideally in front of a whiteboard, that reduces the cycle time typically taken when questions and answers are mediated through phone, persistent chat, wiki, or email.[33] With the widespread adoption of remote working during the COVID-19 pandemic and changes to tooling, more studies have been conducted[34] around co-location and distributed working which show that co-location is increasingly less relevant.
    
    No matter which development method is followed, every team should include a customer representative (known as product owner in Scrum). This representative is agreed by stakeholders to act on their behalf and makes a personal commitment to being available for developers to answer questions throughout the iteration. At the end of each iteration, the project stakeholders together with the customer representative review progress and re-evaluate priorities with a view to optimizing the return on investment (ROI) and ensuring alignment with customer needs and company goals. The importance of stakeholder satisfaction, detailed by frequent interaction and review at the end of each phase, is why the approach is often denoted as a customer-centered methodology.[35]
    
    <h2><b>Information radiator</b></h2>
    In agile software development, an information radiator is a (normally large) physical display, board with sticky notes or similar, located prominently near the development team, where passers-by can see it.[36] It presents an up-to-date summary of the product development status.[37] A build light indicator may also be used to inform a team about the current status of their product development.
    
    <h2><b>Very short feedback loop and adaptation cycle</b></h2>
    A common characteristic in agile software development is the daily stand-up (known as daily scrum in the Scrum framework). In a brief session (e.g., 15 minutes), team members review collectively how they are progressing toward their goal and agree whether they need to adapt their approach. To keep to the agreed time limit, teams often use simple coded questions (such as what they completed the previous day, what they aim to complete that day, and whether there are any impediments or risks to progress), and delay detailed discussions and problem resolution until after the stand-up.[38]
    
    <h2>Quality focus</h2>
    
    Pair programming, an agile development technique used in XP
    Specific tools and techniques, such as continuous integration, automated unit testing, pair programming, test-driven development, design patterns, behavior-driven development, domain-driven design, code refactoring and other techniques are often used to improve quality and enhance product development agility.[39] This is predicated on designing and building quality in from the beginning and being able to demonstrate software for customers at any point, or at least at the end of every iteration.[40]
    
    Philosophy
    Compared to traditional software engineering, agile software development mainly targets complex systems and product development with dynamic, indeterministic and non-linear properties. Accurate estimates, stable plans, and predictions are often hard to get in early stages, and confidence in them is likely to be low. Agile practitioners use their free will to reduce the "leap of faith" that is needed before any evidence of value can be obtained.[41] Requirements and design are held to be emergent. Big up-front specifications would probably cause a lot of waste in such cases, i.e., are not economically sound. These basic arguments and previous industry experiences, learned from years of successes and failures, have helped shape agile development's favor of adaptive, iterative and evolutionary development.[42]
    
    Adaptive vs. predictive
    Development methods exist on a continuum from adaptive to predictive.[43] Agile software development methods lie on the adaptive side of this continuum. One key of adaptive development methods is a rolling wave approach to schedule planning, which identifies milestones but leaves flexibility in the path to reach them, and also allows for the milestones themselves to change.[44]
    
    Adaptive methods focus on adapting quickly to changing realities. When the needs of a project change, an adaptive team changes as well. An adaptive team has difficulty describing exactly what will happen in the future. The further away a date is, the more vague an adaptive method is about what will happen on that date. An adaptive team cannot report exactly what tasks they will do next week, but only which features they plan for next month. When asked about a release six months from now, an adaptive team might be able to report only the mission statement for the release, or a statement of expected value vs. cost.
    
    Predictive methods, in contrast, focus on analyzing and planning the future in detail and cater for known risks. In the extremes, a predictive team can report exactly what features and tasks are planned for the entire length of the development process. Predictive methods rely on effective early phase analysis, and if this goes very wrong, the project may have difficulty changing direction. Predictive teams often institute a change control board to ensure they consider only the most valuable changes.
    
    Risk analysis can be used to choose between adaptive (agile or value-driven) and predictive (plan-driven) methods.[45] Barry Boehm and Richard Turner suggest that each side of the continuum has its own home ground, as follows:[46]</P>

<hr/>
<h1>***UNIFORM RESOURCE LOCATOR (URL)***</h1>
<P>
    For other uses, see URL (disambiguation).
URL
<b>Uniform resource locator</b>
Abbreviation	URL
Status	Published
First published	1994; 30 years ago
Latest version	Living Standard
2023
Organization	Internet Engineering Task Force (IETF)
Committee	Web Hypertext Application Technology Working Group (WHATWG)
Series	Request for Comments (RFC)
Editors	Anne van Kesteren
Authors	Tim Berners-Lee
Base standards	
RFC 1738. – Uniform Resource Locators (URL).
RFC 3986. – Uniform Resource Identifier (URI): Generic Syntax.
RFC 4248. – The telnet URI Scheme.
RFC 4266. – The gopher URI Scheme.
RFC 6068. – The 'mailto' URI Scheme.
RFC 6196. – Moving mailserver: URI Scheme to Historic.
RFC 6270. – The 'tn3270' URI Scheme.
Related standards	URI, URN
Domain	World Wide Web
License	CC BY 4.0
Website	url.spec.whatwg.org
A uniform resource locator (URL), colloquially known as an address on the Web,[1] is a reference to a resource that specifies its location on a computer network and a mechanism for retrieving it. A URL is a specific type of Uniform Resource Identifier (URI),[2][3] although many people use the two terms interchangeably.[4][a] URLs occur most commonly to reference web pages (HTTP/HTTPS) but are also used for file transfer (FTP), email (mailto), database access (JDBC), and many other applications.

Most web browsers display the URL of a web page above the page in an address bar. A typical URL could have the form http://www.example.com/index.html, which indicates a protocol (http), a hostname (www.example.com), and a file name (index.html).

<h2>History</h2>
Uniform Resource Locators were defined in RFC 1738 in 1994 by Tim Berners-Lee, the inventor of the World Wide Web, and the URI working group of the Internet Engineering Task Force (IETF),[7] as an outcome of collaboration started at the IETF Living Documents birds of a feather session in 1992.[7][8]

The format combines the pre-existing system of domain names (created in 1985) with file path syntax, where slashes are used to separate directory and filenames. Conventions already existed where server names could be prefixed to complete file paths, preceded by a double slash (//).[9]

Berners-Lee later expressed regret at the use of dots to separate the parts of the domain name within URIs, wishing he had used slashes throughout,[9] and also said that, given the colon following the first component of a URI, the two slashes before the domain name were unnecessary.[10]

Early WorldWideWeb collaborators including Berners-Lee originally proposed the use of UDIs: Universal Document Identifiers. An early (1993) draft of the HTML Specification[11] referred to "Universal" Resource Locators. This was dropped some time between June 1994 (RFC 1630) and October 1994 (draft-ietf-uri-url-08.txt).[12] In his book Weaving the Web, Berners-Lee emphasizes his preference for the original inclusion of "universal" in the expansion rather than the word "uniform", to which it was later changed, and he gives a brief account of the contention that led to the change.

<h2>Syntax</h2>
Main article: Uniform Resource Identifier § Syntax
Every HTTP URL conforms to the syntax of a generic URI. The URI generic syntax consists of five components organized hierarchically in order of decreasing significance from left to right:[13]: §3 

<b>URI = scheme ":" ["//" authority] path ["?" query] ["#" fragment]</b>
A component is undefined if it has an associated delimiter and the delimiter does not appear in the URI; the scheme and path components are always defined.[13]: §5.2.1  A component is empty if it has no characters; the scheme component is always non-empty.[13]: §3 

The authority component consists of subcomponents:

<b>authority = [userinfo "@"] host [":" port]</b>
This is represented in a syntax diagram as:

URI syntax diagram

The URI comprises:

A non-empty scheme component followed by a colon (:), consisting of a sequence of characters beginning with a letter and followed by any combination of letters, digits, plus (+), period (.), or hyphen (-). Although schemes are case-insensitive, the canonical form is lowercase and documents that specify schemes must do so with lowercase letters. Examples of popular schemes include http, https, ftp, mailto, file, data and irc. URI schemes should be registered with the Internet Assigned Numbers Authority (IANA), although non-registered schemes are used in practice.[b]
An optional authority component preceded by two slashes (//), comprising:
An optional userinfo subcomponent followed by an at symbol (@), that may consist of a user name and an optional password preceded by a colon (:). Use of the format username:password in the userinfo subcomponent is deprecated for security reasons. Applications should not render as clear text any data after the first colon (:) found within a userinfo subcomponent unless the data after the colon is the empty string (indicating no password).
A host subcomponent, consisting of either a registered name (including but not limited to a hostname) or an IP address. IPv4 addresses must be in dot-decimal notation, and IPv6 addresses must be enclosed in brackets ([]).[13]: §3.2.2 [c]
An optional port subcomponent preceded by a colon (:), consisting of decimal digits.
A path component, consisting of a sequence of path segments separated by a slash (/). A path is always defined for a URI, though the defined path may be empty (zero length). A segment may also be empty, resulting in two consecutive slashes (//) in the path component. A path component may resemble or map exactly to a file system path but does not always imply a relation to one. If an authority component is defined, then the path component must either be empty or begin with a slash (/). If an authority component is undefined, then the path cannot begin with an empty segment—that is, with two slashes (//)—since the following characters would be interpreted as an authority component.[16]: §3.3 
By convention, in http and https URIs, the last part of a path is named pathinfo and it is optional. It is composed by zero or more path segments that do not refer to an existing physical resource name (e.g. a file, an internal module program or an executable program) but to a logical part (e.g. a command or a qualifier part) that has to be passed separately to the first part of the path that identifies an executable module or program managed by a web server; this is often used to select dynamic content (a document, etc.) or to tailor it as requested (see also: CGI and PATH_INFO, etc.).
Example:
URI:<strong>"http://www.example.com/questions/3456/my-document"</strong>
where: "/questions" is the first part of the path (an executable module or program) and "/3456/my-document" is the second part of the path named pathinfo, which is passed to the executable module or program named "/questions" to select the requested document.
An <b>http or https </b>URI containing a pathinfo part without a query part may also be referred to as a 'clean URL,' whose last part may be a 'slug.'
Query delimiter	Example
Ampersand (&)	key1=value1&key2=value2
Semicolon (;)[d]	key1=value1;key2=value2
An optional query component preceded by a question mark (?), consisting of a query string of non-hierarchical data. Its syntax is not well defined, but by convention is most often a sequence of attribute–value pairs separated by a delimiter.
An optional fragment component preceded by a hash (#). The fragment contains a fragment identifier providing direction to a secondary resource, such as a section heading in an article identified by the remainder of the URI. When the primary resource is an HTML document, the fragment is often an id attribute of a specific element, and web browsers will scroll this element into view.
A web browser will usually dereference a URL by performing an HTTP request to the specified host, by default on port number 80. URLs using the https scheme require that requests and responses be made over a secure connection to the website.


<h2>Internationalized URL</h2>
Internet users are distributed throughout the world using a wide variety of languages and alphabets, and expect to be able to create URLs in their own local alphabets. An Internationalized Resource Identifier (IRI) is a form of URL that includes Unicode characters. All modern browsers support IRIs. The parts of the URL requiring special treatment for different alphabets are the domain name and path.[18][19]

The domain name in the IRI is known as an Internationalized Domain Name (IDN). Web and Internet software automatically convert the domain name into punycode usable by the Domain Name System; for example, the Chinese URL http://例子.卷筒纸 becomes http://xn--fsqu00a.xn--3lr804guic/. The xn-- indicates that the character was not originally ASCII.[20]

The URL path name can also be specified by the user in the local writing system. If not already encoded, it is converted to UTF-8, and any characters not part of the basic URL character set are escaped as hexadecimal using percent-encoding; for example, the Japanese URL http://example.com/引き割り.html becomes http://example.com/%E5%BC%95%E3%81%8D%E5%89%B2%E3%82%8A.html. The target computer decodes the address and displays the page.[18]

<h2>Protocol-relative URLs</h2>
Protocol-relative links (PRL), also known as protocol-relative URLs (PRURL), are URLs that have no protocol specified. For example, //example.com will use the protocol of the current page, typically HTTP or HTTPS.[21][22]

<h2>See also</h2>
<b>Hyperlink
PURL – Persistent URL
CURIE (Compact URI)
URI fragment
Internet resource locator (IRL)
Internationalized Resource Identifier (IRI)</b>
Clean URL
Typosquatting
Uniform Resource Identifier
URI normalization
Use of slashes in networking
<h2>Notes</h2>
 A URL implies the means to access an indicated resource and is denoted by a protocol or an access mechanism, which is not true of every URI.[5][4] Thus http://www.example.com is a URL, while www.example.com is not.[6]
 The procedures for registering new URI schemes were originally defined in 1999 by RFC 2717, and are now defined by RFC 7595, published in June 2015.[14]
 For URIs relating to resources on the World Wide Web, some web browsers allow .0 portions of dot-decimal notation to be dropped or raw integer IP addresses to be used.[15]
 Historic RFC 1866 (obsoleted by RFC 2854) encourages CGI authors to support ';' in addition to '&'.[17]: §8.2.1 
 <h2>Citations</h2>
 W3C (2009).
 "Forward and Backslashes in URLs". zzz.buzz. Archived from the original on 2018-09-04. Retrieved 2018-09-19.
 RFC 3986 (2005).
 Joint W3C/IETF URI Planning Interest Group (2002).
 RFC 2396 (1998).
 Miessler, Daniel. "The Difference Between URLs and URIs". Archived from the original on 2017-03-17. Retrieved 2017-03-16.
 W3C (1994).
 IETF (1992).
 Berners-Lee (2015).
 BBC News (2009).
 Berners-Lee, Tim; Connolly, Daniel "Dan" (March 1993). Hypertext Markup Language (draft RFCxxx) (Technical report). p. 28. Archived from the original on 2017-10-23. Retrieved 2017-10-23.
 Berners-Lee, Tim; Masinter, Larry; McCahill, Mark Perry (October 1994). Uniform Resource Locators (URL) (Technical report). (This Internet-Draft was published as a Proposed Standard RFC, RFC 1738 (1994)) Cited in Ang, C. S.; Martin, D. C. (January 1995). Constituent Component Interface++ (Technical report). UCSF Library and Center for Knowledge Management. Archived from the original on 2017-10-23. Retrieved 2017-10-23.
 T. Berners-Lee; R. Fielding; L. Masinter (January 2005). Uniform Resource Identifier (URI): Generic Syntax. Network Working Group. doi:10.17487/RFC3986. STD 66. RFC 3986. Internet Standard 66. Obsoletes RFC 2732, 2396 and 1808. Updated by RFC 6874, 7320 and 8820. Updates RFC 1738.
 Hansen, Tony; Hardie, Ted (June 2015). Thaler, Dave (ed.). Guidelines and Registration Procedures for URI Schemes. Internet Engineering Task Force. doi:10.17487/RFC7595. ISSN 2070-1721. BCP 35. RFC 7595. Best Current Practice. Updated by RFC 8615. Obsoletes RFC 4395.
 Lawrence (2014).
 T. Berners-Lee; R. Fielding; L. Masinter (August 1998). Uniform Resource Identifiers (URI): Generic Syntax. Network Working Group. doi:10.17487/RFC2396. RFC 2396. Obsolete. Obsoleted by RFC 3986. Updated by RFC 2732. Updates RFC 1808 and 1738.
 Berners-Lee, Tim; Connolly, Daniel W. (November 1995). Hypertext Markup Language - 2.0. Network Working Group. doi:10.17487/RFC1866. RFC 1866. Historic. Obsoleted by RFC 2854.
 W3C (2008).
 W3C (2014).
 IANA (2003).
 Glaser, J. D. (2014-03-10). Secure Development for Mobile Apps: How to Design and Code Secure Mobile Applications with PHP and JavaScript (1st ed.). CRC Press. p. 193. ISBN 978-1-48220903-7. Retrieved 2015-10-12.
 Schafer, Steven M. (2011). HTML, XHTML, and CSS Bible (1st ed.). John Wiley & Sons. p. 124. ISBN 978-1-11808130-3. Retrieved 2015-10-12.
 <h2>References</h2>
 <li>"Berners-Lee "sorry" for slashes". BBC News. 2009-10-14. Archived from the original on 2020-06-05. Retrieved 2010-02-14.</li>
 <li>"Living Documents BoF Minutes". World Wide Web Consortium. 1992-03-18. Archived from the original on 2012-11-22. Retrieved 2011-12-26.</li>
 <li>Berners-Lee, Tim (1994-03-21). "Uniform Resource Locators (URL): A Syntax for the Expression of Access Information of Objects on the Network". World Wide Web Consortium. Archived from the original on 2015-09-09. Retrieved 2015-09-13.</li>
 <li>Berners-Lee, Tim; Masinter, Larry; McCahill, Mark Perry (December 1994). Uniform Resource Locators (URL). doi:10.17487/RFC1738. RFC 1738. Retrieved 2015-08-31.</li>
 <li>Berners-Lee, Tim (2015) [2000]. "Why the //, #, etc?". Frequently asked questions. World Wide Web Consortium. Archived from the original on 2020-05-14. Retrieved 2010-02-03.</li>
Connolly, Daniel "Dan"; Sperberg-McQueen, C. Michael, eds. (2009-05-21). "Web addresses in HTML 5". World Wide Web Consortium. Archived from the original on 2015-07-10. Retrieved 2015-09-13.
IANA (2003-02-14). "Completion of IANA Selection of IDNA Prefix". IETF-Announce mailing list. Archived from the original on 2004-12-08. Retrieved 2015-09-03.
<p>Berners-Lee, Tim; Connolly, Daniel "Dan" (November 1995). "Hypertext Markup Language – 2.0". IETF Datatracker. Internet Engineering Task Force. sec. 8.2.1. doi:10.17487/RFC1866. S2CID 6628570. RFC 1866. Retrieved 2015-09-13.
Berners-Lee, Tim; Fielding, Roy T.; Masinter, Larry (August 1998). Uniform Resource Identifiers (URI): Generic Syntax. doi:10.17487/RFC2396. RFC 2396. Retrieved 2015-08-31.
Hansen, Tony; Hardie, Ted (June 2015). Thaler, Dave (ed.). Guidelines and Registration Procedures for URI Schemes. doi:10.17487/RFC7595. RFC 7595.
Mealling, Michael; Denenberg, Ray, eds. (August 2002). Report from the Joint W3C/IETF URI Planning Interest Group: Uniform Resource Identifiers (URIs), URLs, and Uniform Resource Names (URNs): Clarifications and Recommendations. doi:10.17487/RFC3305. RFC 3305. Retrieved 2015-09-13.
Berners-Lee, Tim; Fielding, Roy T.; Masinter, Larry (January 2005). Uniform Resource Identifiers (URI): Generic Syntax. doi:10.17487/RFC3986. RFC 3986. Retrieved 2015-08-31.
Berners-Lee, Tim; Fielding, Roy T.; Masinter, Larry (January 2005). "Syntax Components". Uniform Resource Identifiers (URI): Generic Syntax. sec. 3. doi:10.17487/RFC3986. RFC 3986. Retrieved 2015-08-31.
"An Introduction to Multilingual Web Addresses". 2008-05-09. Archived from the original on 2015-01-05. Retrieved 2015-01-11.</p>
Phillip, A. (2014). "What is Happening with "International URLs"". World Wide Web Consortium. Archived from the original on 2015-02-17. Retrieved 2015-01-11.
Lawrence, Eric (2014-03-06). "Browser Arcana: IP Literals in URLs". Microsoft Learn. Archived from the original on 2020-06-22. Retrieved 2020-06-22.
</P>
<HR/>
<h1>SYSTEMS DEVELOPMENT LIFE CYCLE (SDLC)</h1>
<Marquee>class 17/12/24
</Marquee>
<p>In systems engineering, information systems and software engineering, the <b>systems development life cycle (SDLC)</b>, also referred to as the <b>application development life cycle</b>, is a process for planning, creating, testing, and deploying an information system.[1] The SDLC concept applies to a range of hardware and software configurations, as a system can be composed of hardware only, software only, or a combination of both.[2] There are usually six stages in this cycle: requirement analysis, design, development and testing, implementation, documentation, and evaluation.</p>

    <p>"Software development organization follows some process when developing a Software product in <b>mature organization</b> this is well defined and managed. In Software development life cycle, we develop Software in a <b>Systematic and disciplined manner."</b></p>
    
    <h2>Overview</h2>
   <p> A systems development life cycle is composed of distinct work phases that are used by systems engineers and systems developers to deliver information systems. Like anything that is manufactured on an assembly line, an SDLC aims to produce high-quality systems that meet or exceed expectations, based on requirements, by delivering systems within scheduled time frames and cost estimates.[3] Computer systems are complex and often link components with varying origins. Various SDLC methodologies have been created, such as waterfall, spiral, agile, rapid prototyping, incremental, and synchronize and stabilize.[4]</p>
    
    <p>SDLC methodologies fit within a flexibility spectrum ranging from agile to iterative to sequential. Agile methodologies, such as XP and Scrum, focus on lightweight processes that allow for rapid changes.[5] Iterative methodologies, such as Rational Unified Process and dynamic systems development method, focus on stabilizing project scope and iteratively expanding or improving products. Sequential or big-design-up-front (BDUF) models, such as waterfall, focus on complete and correct planning to guide larger projects and limit risks to successful and predictable results.[6] Anamorphic development is guided by project scope and adaptive iterations.</p>
    
   <p>In project management a project can include both a project life cycle (PLC) and an SDLC, during which somewhat different activities occur. According to Taylor (2004), "the project life cycle encompasses all the activities of the project, while the systems development life cycle focuses on realizing the product requirements".[7]</p>
    
    <p>SDLC is not a methodology per se, but rather a description of the phases that a methodology should address. The list of phases is not definitive, but typically includes planning, analysis, design, build, test, implement, and maintenance/support. In the Scrum framework,[8] for example, one could say a single user story goes through all the phases of the SDLC within a two-week sprint. By contrast the waterfall methodology, where every business requirement[citation needed] is translated into feature/functional descriptions which are then all implemented typically over a period of months or longer.[citation needed]</p>

    <h2>History</h2>
   <p>According to Elliott (2004), SDLC "originated in the 1960s, to develop large scale functional business systems in an age of large scale business conglomerates. Information systems activities revolved around heavy data processing and number crunching routines".[9]</p>
    
    <p>The structured systems analysis and design method (SSADM) was produced for the UK government Office of Government Commerce in the 1980s. Ever since, according to Elliott (2004), "the traditional life cycle approaches to systems development have been increasingly replaced with alternative approaches and frameworks, which attempted to overcome some of the inherent deficiencies of the traditional SDLC".[9]</p>

    <h2>Models</h2>
    
  <p> A ten-phase version of the systems development life cycle[10]
    
    This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (January 2024) (Learn how and when to remove this message)
    SDLC provides a set of phases/steps/activities for system designers and developers to follow. Each phase builds on the results of the previous one.[10][11][12][13] Not every project requires that the phases be sequential. For smaller, simpler projects, phases may be combined/overlap.[10]</p>
    <h2>Waterfall</h2>
   <p>The oldest and best known is the waterfall model, which uses a linear sequence of steps.[11] Waterfall has different varieties. One variety is as follows:[10][11][14][15]</p>
    
    <h2>Preliminary analysis</h2>
    <p>Conduct with a preliminary analysis, consider alternative solutions, estimate costs and benefits, and submit a preliminary plan with recommendations.</p>
    
    <li>Conduct preliminary analysis: Identify the organization's objectives and define the nature and scope of the project. Ensure that the project fits with the objectives.</li>
   <li> Consider alternative solutions: Alternatives may come from interviewing employees, clients, suppliers, and consultants, as well as competitive analysis.</li>
    <li>Cost-benefit analysis: Analyze the costs and benefits of the project.</li>
    <h2>Systems analysis, requirements definition</h2>
   <p>Decompose project goals[clarification needed] into defined functions and operations. This involves gathering and interpreting facts, diagnosing problems, and recommending changes. Analyze end-user information needs and resolve inconsistencies and incompleteness:[16]</p>
    
   <li> Collect facts: Obtain end-user requirements by document review, client interviews, observation, and questionnaires.</li>
    <li>Scrutinize existing system(s): Identify pros and cons.</li>
   <li>Analyze the proposed system: Find solutions to issues and prepare specifications, incorporating appropriate user proposals.</li>
    <h2>Systems design</h2>
    At this step, desired features and operations are detailed, including screen layouts,<b>business rules, process diagrams, pseudocode</b>, and other deliverables.
    
    <h2>Development</h2>
    Write the code.
    
    <h2>Integration and testing</h2>
    Assemble the modules in a testing environment. Check for errors, bugs, and interoperability.
    
   <h2>Acceptance, installation, deployment</h2>
    Put the system into production. This may involve training users, deploying hardware, and loading information from the prior system.
    
   <h2> Maintenance</h2>
    Monitor the system to assess its ongoing fitness. Make modest changes and fixes as needed. To maintain the quality of the system. Continual monitoring and updates ensure the system remains effective and high-quality.[17]
    
   <h2>Evaluation</h2>
    The system and the process are reviewed. Relevant questions include whether the newly implemented system meets requirements and achieves project goals, whether the system is usable, reliable/available, properly scaled and fault-tolerant. Process checks include review of timelines and expenses, as well as user acceptance.
    
    <h2>Disposal</h2>
    <p>At end of life, plans are developed for discontinuing the system and transitioning to its replacement. Related information and infrastructure must be repurposed, archived, discarded, or destroyed, while appropriately protecting security.[18]</p>
    
    <p>In the following diagram, these stages are divided into ten steps, from definition to creation and modification of IT work products:</p>
    
    <h2>Systems analysis and design</h2>
    <b>Systems analysis and design (SAD) </b>can be considered a meta-development activity, which serves to set the stage and bound the problem. SAD can help balance competing high-level requirements. SAD interacts with distributed enterprise architecture, enterprise I.T. Architecture, and business architecture, and relies heavily on concepts such as partitioning, interfaces, personae and roles, and deployment/operational modeling to arrive at a high-level system description. This high-level description is then broken down into the components and modules which can be analyzed, designed, and constructed separately and integrated to accomplish the business goal. SDLC and SAD are cornerstones of full life cycle product and system planning.
    
    <h2>Object-oriented analysis and design</h2>
   <p><b>Object-oriented analysis and design (OOAD)</b> is the process of analyzing a problem domain to develop a conceptual model that can then be used to guide development. During the analysis phase, a programmer develops written requirements and a formal vision document via interviews with stakeholders.</p>
    
    The conceptual model that results from OOAD typically consists of use cases, and class and interaction diagrams. It may also include a user interface mock-up.
    
    <p>An output artifact does not need to be completely defined to serve as input of object-oriented design; analysis and design may occur in parallel. In practice the results of one activity can feed the other in an iterative process.</p>
    
    Some typical input artifacts for<b>OOAD</b>:
    
    <li><b>Conceptual model</b>: A conceptual model is the result of object-oriented analysis. It captures concepts in the problem domain. The conceptual model is explicitly independent of implementation details.</li>
    <li><b>Use cases</b>: A use case is a description of sequences of events that, taken together, complete a required task. Each use case provides scenarios that convey how the system should interact with actors (users). Actors may be end users or other systems. Use cases may further elaborated using diagrams. Such diagrams identify the actor and the processes they perform.</li>
    <li><b>System Sequence Diagram: A System Sequence diagrams (SSD) is a picture that shows, for a particular use case, the events that actors generate, their order, including inter-system events.</b></li>
    <li>User interface document: Document that shows and describes the user interface.</li>
<li><b>Data model</b>: A data model describes how data elements relate to each other. The data model is created before the design phase. Object-oriented designs map directly from the data model. Relational designs are more involved.</li>
    <h2>System lifecycle</h2>
    The system lifecycle is a view of a system or proposed system that addresses all phases of its existence to include system conception, design and development, production and/or construction, distribution, operation, maintenance and support, retirement, phase-out, and disposal.[19]
    
    <h2>Conceptual design</h2>
    The <b>conceptual design </b>stage is the stage where an identified need is examined, requirements for potential solutions are defined, potential solutions are evaluated, and a system specification is developed. The system specification represents the technical requirements that will provide overall guidance for system design. Because this document determines all future development, the stage cannot be completed until a conceptual <b>design review </b>has determined that the system specification properly addresses the motivating need.
    
    <p>Key steps within the conceptual design stage include:</p>
    
   <li> Need identification</li>
   <li>Feasibility analysis</li>
   <li> System requirements analysis</li>
   <li>System specification</li>
   <li> Conceptual design review</li>
    <h2>Preliminary system design</h2>
    During this stage of the system lifecycle, subsystems that perform the desired system functions are designed and specified in compliance with the system specification. Interfaces between subsystems are defined, as well as overall test and evaluation requirements.[20] At the completion of this stage, a development specification is produced that is sufficient to perform detailed design and development.
    
    <p>Key steps within the preliminary design stage include:</p>
    
    <li>Functional analysisw</li>
    <li>Requirements allocation</li>
    <li>Detailed trade-off studies</li>
    <li>Synthesis of system options</li>
    <li>Preliminary design of engineering models</li>
    <li>Development specification</li>
    <li>Preliminary design review</li>
    For example, as the system analyst of Viti Bank, you have been tasked to examine the current information system. Viti Bank is a fast-growing bank in Fiji. Customers in remote rural areas are finding difficulty to access the bank services. It takes them days or even weeks to travel to a location to access the bank services. With the vision of meeting the customers' needs, the bank has requested your services to examine the current system and to come up with solutions or recommendations of how the current system can be provided to meet its needs.
    
    <h2>Detail design and development</h2>
    This stage includes the development of detailed designs that brings initial design work into a completed form of specifications. This work includes the specification of interfaces between the system and its intended environment, and a comprehensive evaluation of the systems logistical, maintenance and support requirements. The detail design and development is responsible for producing the product, process and material specifications and may result in substantial changes to the development specification.
    
    Key steps within the detail design and development stage include:
    
    <li>Detailed design and development</li>
        <li> Detailed synthesis</li>
        <li>Development of engineering and <b>prototype</b> models</li>
        <li> Revision of development specification</li>
        <li>Product, process, and material specification</li>
        <li>Critical design review</li>
    <h2>Production and construction</h2>
    During the production and/or construction stage the product is built or assembled in accordance with the requirements specified in the product, process and material specifications, and is deployed and tested within the operational target environment. System assessments are conducted in order to correct deficiencies and adapt the system for continued improvement.
    
<p>Key steps within the product construction stage include:</p>
    
<li> Production and/or construction of system components</li>
<li>Acceptance testing</li>
<li>System distribution and operation</li>
<li>Operational testing and evaluation</li>
    <li> System assessment</li>
   <h2>Utilization and support</h2>
    Once fully deployed, the system is used for its intended operational role and maintained within its operational environment.
    
   <p> Key steps within the utilization and support stage include:</p>
    
   <li>System operation in the user environment</li>
   <li>Change management</li>
    <li>System modifications for improvement</li>
<li> System assessment</li>

   <h2> Phase-out and disposal</h2>
    Effectiveness and efficiency of the system must be continuously evaluated to determine when the product has met its maximum effective lifecycle.[21] Considerations include: Continued existence of operational need, matching between operational requirements and system performance, feasibility of system phase-out versus maintenance, and availability of alternative systems.
    
    <h2>Phases</h2>
    
    This section includes a list of references, related reading, or external links, but its sources remain unclear because it lacks inline citations. Please help improve this section by introducing more precise citations. (January 2023) (Learn how and when to remove this message)
   <h2>System investigation</h2>
    During this step, current priorities that would be affected and how they should be handled are considered. A <b>feasibility study</b> determines whether creating a new or improved system is appropriate. This helps to estimate costs, benefits, resource requirements, and specific user needs.
    
    The feasibility study should address<b> operational, financial, technical,</b> human factors, and legal/political concerns.
    
    <h2>Analysis</h2>
    The goal of <b>analysis</b> is to determine where the problem is. This step involves decomposing the system into pieces, analyzing project goals, breaking down what needs to be created, and engaging users to define requirements.
    
   <h2> Design</h2>
    In <b>systems design</b>, functions and operations are described in detail, including screen layouts, business rules, process diagrams, and other documentation. Modular design reduces complexity and allows the outputs to describe the system as a collection of subsystems.
    
    <p>The design stage takes as its input the requirements already defined. For each requirement, a set of design elements is produced.</p>
    
    Design documents typically include functional hierarchy diagrams, screen layouts, business rules, process diagrams, pseudo-code, and a complete data model with a data dictionary. These elements describe the system in sufficient detail that developers and engineers can develop and deliver the system with minimal additional input.
    
    <h2>Testing</h2>
    The code is tested at various levels in <b>software testing</b>. Unit, system, and user acceptance tests are typically performed. Many approaches to testing have been adopted.
    
    <p>The following types of testing may be relevant:</p>
    
    <li>Path testing</li>
    <li>Data set testing</li>
    <li>Unit testing</li>
    <li>System testing</li>
   <li>integration testing</li>
   <li>Black-box testing</li>
   <li>White-box testing</li>
   <li>Regression testing</li>
   <li>Automation testing</li>
   <li>User acceptance testing</li>
   <li>Software performance testing</li>
    <h2>Training and transition</h2>
    Once a system has been stabilized through testing, SDLC ensures that proper training is prepared and performed before transitioning the system to support staff and end users. Training usually covers operational training for support staff as well as end-user training.
    
   <p> After training, systems engineers and developers transition the system to its production environment.</p>
    
    <h2>Operations and maintenance</h2>
    <b>Maintenance</b> includes changes, fixes, and enhancements.
    
    <h2>Evaluation</h2>
    The final phase of the SDLC is to measure the effectiveness of the system and evaluate potential enhancements.
    
    <h2>Life cycle</h2>
    <h3>Management and control</h3>
    
    SDLC phases related to management controls[22]
    SDLC phase objectives are described in this section with key deliverables, a description of recommended tasks, and a summary of related control objectives for effective management. It is critical for the project manager to establish and monitor control objectives while executing projects. Control objectives are clear statements of the desired result or purpose and should be defined and monitored throughout a project. Control objectives can be grouped into major categories (domains), and relate to the SDLC phases as shown in the figure.[22]
    
   <p>To manage and control a substantial SDLC initiative, a <b>work breakdown structure (WBS)</b> captures and schedules the work. The WBS and all programmatic material should be kept in the "project description" section of the project notebook.[clarification needed] The project manager chooses a WBS format that best describes the project.</p>
    
    <p>The diagram shows that coverage spans numerous phases of the SDLC but the associated MCD (Management Control Domains) shows mappings to SDLC phases. For example, Analysis and Design is primarily performed as part of the Acquisition and Implementation Domain, and System Build and Prototype is primarily performed as part of delivery and support.[22]</p>
    
    <h3>Work breakdown structured organization</h3>
    
    The upper section of the WBS provides an overview of the project scope and timeline. It should also summarize the major phases and milestones. The middle section is based on the SDLC phases. WBS elements consist of milestones and tasks to be completed rather than activities to be undertaken and have a deadline. Each task has a measurable output (e.g., analysis document). A WBS task may rely on one or more activities (e.g. coding). Parts of the project needing support from contractors should have a statement of work (SOW). The development of a SOW does not occur during a specific phase of SDLC but is developed to include the work from the SDLC process that may be conducted by contractors.[22]
    
    <h3>Baselines</h3>
    Baselines<b>[clarification needed]</b> are established after four of the five phases of the SDLC, and are critical to the iterative nature of the model.[23] Baselines become milestones.
    
    <li>functional baseline: established after the conceptual design phase.</li>
    <li> allocated baseline: established after the preliminary design phase.</li>
    <li> product baseline: established after the detail design and development phase.</li>
    <li>updated product baseline: established after the production construction phase.</li>
   <h3> Alternative methodologies</h3>
    Alternative <b>software development methods</b> to systems development life cycle are: 
<li>Software prototyping</li>
<li>Joint applications development (JAD)</li>
<li>Rapid application development (RAD)</li>
<li>Extreme programming (XP);</li>
<li> Open-source development</li>
<li> End-user development</li>
<li>Object-oriented programming</li>
    <h3>See also</h3>
    <li>Application lifecycle management</li>
    <li>Decision cycle</li>
    <li>IPO model</li>
    <li> Software development methodologies</li>
</p>
</body>
</html>